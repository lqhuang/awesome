# Research

## Resources

- [illustrated-machine-learning/illustrated-machine-learning.github.io](https://github.com/illustrated-machine-learning/illustrated-machine-learning.github.io): Website containing illustrations about Machine Learning theory! <https://illustrated-machine-learning.github.io>
- [soulmachine/machine-learning-cheat-sheet](https://github.com/soulmachine/machine-learning-cheat-sheet): Classical equations and diagrams in machine learning <http://soulmachine.me>
- [harvardnlp/annotated-transformer](https://github.com/harvardnlp/annotated-transformer): An annotated implementation of the Transformer paper. <http://nlp.seas.harvard.edu/annotated-transformer>
- [vdumoulin/conv_arithmetic](https://github.com/vdumoulin/conv_arithmetic): A technical report on convolution arithmetic in the context of deep learning
- [How GPT3 Works - Visualizations and Animations](https://jalammar.github.io/how-gpt3-works-visualizations-animations/)
- [jessevig/bertviz](https://github.com/jessevig/bertviz): BertViz: Visualize Attention in NLP Models (BERT, GPT2, BART, etc.) <https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1>
- [lutzroeder/netron](https://github.com/lutzroeder/netron): Visualizer for neural network, deep learning and machine learning models <https://netron.app>
- [dataflowr/notebooks](https://github.com/dataflowr/notebooks): code for deep learning courses <http://www.dataflowr.com/>
- [dyweb/papers-notebook](https://github.com/dyweb/papers-notebook): ğŸ“„ ğŸ‡¨ğŸ‡³ ğŸ“ƒ è®ºæ–‡é˜…è¯»ç¬”è®°ï¼ˆåˆ†å¸ƒå¼ç³»ç»Ÿã€è™šæ‹ŸåŒ–ã€æœºå™¨å­¦ä¹ ï¼‰Papers Notebook (Distributed System, Virtualization, Machine Learning) ç›®å‰ä¸å†ä»¥ Markdown æ–‡ä»¶çš„æ–¹å¼ç»´æŠ¤ï¼Œè½¬åˆ° issue é¡µé¢è¿›è¡Œï¼Œä¹Ÿæ¬¢è¿åˆ°è¿™ä¸ª issue ä¸­åˆ†äº«æ‚¨è®¤ä¸ºå€¼å¾—ä¸€è¯»çš„ paper
- [å¼ºåŒ–å­¦ä¹  100 é¢˜ - by æ–è—¤åº·æ¯… (Koki Saitoh)](https://p100.koki-saitoh.com/zh-CN)
- [xiaolincoder/CS-Base](https://github.com/xiaolincoder/CS-Base): å›¾è§£è®¡ç®—æœºç½‘ç»œã€æ“ä½œç³»ç»Ÿã€è®¡ç®—æœºç»„æˆã€æ•°æ®åº“ï¼Œå…± 1000 å¼ å›¾ + 50 ä¸‡å­—ï¼Œç ´é™¤æ™¦æ¶©éš¾æ‡‚çš„è®¡ç®—æœºåŸºç¡€çŸ¥è¯†ï¼Œè®©å¤©ä¸‹æ²¡æœ‰éš¾æ‡‚çš„å…«è‚¡æ–‡ï¼ğŸš€ <https://xiaolincoding.com>
- [google-deepmind/deepmind-research](https://github.com/google-deepmind/deepmind-research): This repository contains implementations and illustrative code to accompany DeepMind publications
- [poloclub/transformer-explainer](https://github.com/poloclub/transformer-explainer): Learn How Transformers work in Generative AI with Interactive Visualization <https://poloclub.github.io/transformer-explainer/>
- [poloclub/cnn-explainer](https://github.com/poloclub/cnn-explainer): Learning Convolutional Neural Networks with Interactive Visualization. <https://poloclub.github.io/cnn-explainer/>
- [poloclub/diffusion-explainer](https://github.com/poloclub/diffusion-explainer): Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion <https://poloclub.github.io/diffusion-explainer/>
- [poloclub/ganlab](https://github.com/poloclub/ganlab): GAN Lab: An Interactive, Visual Experimentation Tool for Generative Adversarial Networks <https://poloclub.github.io/ganlab/>
- [The Matrix Calculus You Need For Deep Learning](https://explained.ai/matrix-calculus/)
  - [parrt/website-explained.ai](https://github.com/parrt/website-explained.ai): The website content for explained.ai
- [Practical Deep Learning for Coders](https://course.fast.ai/)
- [papers-we-love/papers-we-love](https://github.com/papers-we-love/papers-we-love): Papers from the computer science community to read and discuss. <http://paperswelove.org/>
- [Jason2Brownlee/MachineLearningMischief](https://github.com/Jason2Brownlee/MachineLearningMischief): Machine Learning Mischief: Examples from the dark side of data science
- [google-deepmind/educational](https://github.com/google-deepmind/educational): This repository contains a collection of educational tutorials that we have prepared for teaching the basics of machine learning to various audiences.
- [julrog/nn_vis](https://github.com/julrog/nn_vis): A project for processing neural networks and rendering to gain insights on the architecture and parameters of a model through a decluttered representation.
- [gavinkhung/machine-learning-visualized](https://github.com/gavinkhung/machine-learning-visualized): ML algorithms implemented and derived from first-principles in Jupyter Notebooks and NumPy <https://ml-visualized.com/>

## Readings

- ğŸŒŸ [Home - colah's blog](https://colah.github.io/)
- [mli/paper-reading](https://github.com/mli/paper-reading): æ·±åº¦å­¦ä¹ ç»å…¸ã€æ–°è®ºæ–‡é€æ®µç²¾è¯»
- ğŸŒŸ [graykode/distribution-is-all-you-need](https://github.com/graykode/distribution-is-all-you-need): The basic distribution probability Tutorial for Deep Learning Researchers
- [labmlai/annotated_deep_learning_paper_implementations](https://github.com/labmlai/annotated_deep_learning_paper_implementations): ğŸ§‘â€ğŸ« 60 Implementations/tutorials of deep learning papers with side-by-side notes ğŸ“; including transformers (original, xl, switch, feedback, vit, ...), optimizers (adam, adabelief, sophia, ...), gans(cyclegan, stylegan2, ...), ğŸ® reinforcement learning (ppo, dqn), capsnet, distillation, ... ğŸ§  <https://nn.labml.ai>
- [Patrick Kidger: Just know stuff](https://kidger.site/thoughts/just-know-stuff/): Or, how to achieve success in a machine learning PhD.
- [dair-ai/ML-Papers-Explained](https://github.com/dair-ai/ML-Papers-Explained): Explanation to key concepts in ML

## Books

- ğŸŒŸ [probml/pml-book](https://github.com/probml/pml-book): "Probabilistic Machine Learning" - a book series by Kevin Murphy
  - [Book 0: "Machine Learning: A Probabilistic Perspective" (2012)](https://probml.github.io/pml-book/book0.html)
  - [Book 1: "Probabilistic Machine Learning: An Introduction" (2022)](https://probml.github.io/pml-book/book1.html)
  - [Book 2: "Probabilistic Machine Learning: Advanced Topics" (2023)](https://probml.github.io/pml-book/book2.html)
- ğŸŒŸ [udlbook/udlbook](https://github.com/udlbook/udlbook): Understanding Deep Learning - Simon J.D. Prince
  - [careywyr/UnderstandingDeepLearning-ZH-CN](https://github.com/careywyr/UnderstandingDeepLearning-ZH-CN): UnderstandingDeepLearing ä¸­æ–‡ç¿»è¯‘
- [nndl/nndl.github.io](https://github.com/nndl/nndl.github.io): ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹ é‚±é”¡é¹è‘— Neural Network and Deep Learning <https://nndl.github.io/>
- [datawhalechina/leedl-tutorial](https://github.com/datawhalechina/leedl-tutorial): ã€Šæå®æ¯…æ·±åº¦å­¦ä¹ æ•™ç¨‹ã€‹
- [CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers): aka "Bayesian Methods for Hackers": An introduction to Bayesian methods + probabilistic programming with a computation/understanding-first, mathematics-second point of view. All in pure Python ;) <http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/>
- [Underactuated Robotics](https://underactuated.mit.edu/): Algorithms for Walking, Running, Swimming, Flying, and Manipulation
- ğŸŒŸ [harvard-edge/cs249r_book](https://github.com/harvard-edge/cs249r_book): Collaborative book Machine Learning Systems <https://harvard-edge.github.io/cs249r_book/>
- [d2l-ai/d2l-zh](https://github.com/d2l-ai/d2l-zh): ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹ï¼šé¢å‘ä¸­æ–‡è¯»è€…ã€èƒ½è¿è¡Œã€å¯è®¨è®ºã€‚ä¸­è‹±æ–‡ç‰ˆè¢« 60 ä¸ªå›½å®¶çš„ 400 æ‰€å¤§å­¦ç”¨äºæ•™å­¦ã€‚ <http://zh.d2l.ai>
- [natolambert/rlhf-book](https://github.com/natolambert/rlhf-book): Textbook on reinforcement learning from human feedback <https://rlhfbook.com/>
- ğŸŒŸ [Ma-Lab-Berkeley/deep-representation-learning-book](https://github.com/Ma-Lab-Berkeley/deep-representation-learning-book): Learning Deep Representations of Data Distributions <https://ma-lab-berkeley.github.io/deep-representation-learning-book/>
- [A Data-Centric Introduction to Computing](https://dcic-world.org/)

## Workshop

- [Differentiable Almost Everything: Differentiable Relaxations, Algorithms, Operators, and Simulators](https://differentiable.xyz)
- [Structured Probabilistic Inference and Generative Modeling](https://icml.cc/virtual/2023/workshop/21469)

## Reinforcement Learning

- [DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3): PyTorch version of Stable Baselines, reliable implementations of reinforcement learning algorithms. <https://stable-baselines3.readthedocs.io>
- [vwxyzjn/cleanrl](https://github.com/vwxyzjn/cleanrl): High-quality single file implementation of Deep Reinforcement Learning algorithms with research-friendly features (PPO, DQN, C51, DDPG, TD3, SAC, PPG) <http://docs.cleanrl.dev>
- [ikostrikov/jaxrl](https://github.com/ikostrikov/jaxrl): JAX (Flax) implementation of algorithms for Deep Reinforcement Learning with continuous action spaces.
- [facebookresearch/MLGym](https://github.com/facebookresearch/MLGym): MLGym A New Framework and Benchmark for Advancing AI Research Agents
- [epignatelli/navix](https://github.com/epignatelli/navix): Accelerated minigrid environments with JAX
- [anyscale/rl-course](https://github.com/anyscale/rl-course)
- [RLHFlow/Minimal-RL](https://github.com/RLHFlow/Minimal-RL)
- [FareedKhan-dev/all-rl-algorithms](https://github.com/FareedKhan-dev/all-rl-algorithms): Implementation of all RL algorithms in a simpler way
- [Reinforcement Learning Guide | Unsloth Documentation](https://docs.unsloth.ai/basics/reinforcement-learning-guide)
- [An Incomplete Theory for RL â€“ Gene Li](https://gene.ttic.edu/blog/incomplete-rl): no description found
- [MathFoundationRL/Book-Mathematical-Foundation-of-Reinforcement-Learning](https://github.com/MathFoundationRL/Book-Mathematical-Foundation-of-Reinforcement-Learning): This is the homepage of a new book entitled "Mathematical Foundations of Reinforcement Learning."

## Flow models

- [francois-rozet/zuko](https://github.com/francois-rozet/zuko): Normalizing flows in PyTorch <https://zuko.readthedocs.io>
- [janosh/awesome-normalizing-flows](https://github.com/janosh/awesome-normalizing-flows): Awesome resources on normalizing flows.
- [facebookresearch/lagrangian-ot](https://github.com/facebookresearch/lagrangian-ot): Neural Optimal Transport with Lagrangian Costs
- [gpeyre/ot4ml](https://github.com/gpeyre/ot4ml): Optimal Transport for Machine Learners
- [yifan123/flow_grpo](https://github.com/yifan123/flow_grpo): An official implementation of Flow-GRPO: Training Flow Matching Models via Online RL <https://arxiv.org/pdf/2505.05470>

## Differentiable programming / PDE / ODE / SDE

- [Useful Algorithms That Are Not Optimized By Jax, PyTorch, or Tensorflow - Stochastic Lifestyle](https://www.stochasticlifestyle.com/useful-algorithms-that-are-not-optimized-by-jax-pytorch-or-tensorflow/)
- [google-research/torchsde](https://github.com/google-research/torchsde): Differentiable SDE solvers with GPU support and efficient sensitivity analysis.
- [rtqichen/torchdiffeq](https://github.com/rtqichen/torchdiffeq): Differentiable ODE solvers with full GPU support and O(1)-memory backpropagation.
- ğŸŒŸ [tum-pbs/pbdl-book](https://github.com/tum-pbs/pbdl-book): Welcome to the Physics-based Deep Learning Book (v0.2) <https://physicsbaseddeeplearning.org/>
- [tum-pbs/PhiFlow](https://github.com/tum-pbs/PhiFlow): A differentiable PDE solving framework for machine learning
- [microsoft/pdearena](https://github.com/microsoft/pdearena): A modern, scalable, and easy to use PDE Surrogate Benchmarking Framework. <https://microsoft.github.io/pdearena>
- ğŸŒŸ [Zymrael/awesome-neural-ode](https://github.com/Zymrael/awesome-neural-ode): A collection of resources regarding the interplay between differential equations, deep learning, dynamical systems, control and numerical methods.
- [risteskilab/deq-neural-operators](https://github.com/risteskilab/deq-neural-operators): Deep Equilibrium Based Neural Operators for Steady State PDEs
- [y1xiaoc/fwdlap](https://github.com/y1xiaoc/fwdlap): Forward mode laplacian implemented in JAX tracer <https://github.com/y1xiaoc/fwdlap>
- [microsoft/folx](https://github.com/microsoft/folx): Implementation of Forward Laplacian algorithm in JAX
- [ExtensityAI/symbolicai](https://github.com/ExtensityAI/symbolicai): Compositional Differentiable Programming Library
- [NVIDIA/physicsnemo](https://github.com/NVIDIA/physicsnemo): Open-source deep-learning framework for building, training, and fine-tuning deep learning models using state-of-the-art Physics-ML methods <https://developer.nvidia.com/physicsnemo>
- [peterparity/symder](https://github.com/peterparity/symder): SymDer: Symbolic Derivative Approach to Discovering Sparse Interpretable Dynamics from Partial Observations <https://doi.org/10.1038/s42005-022-00987-z>
  - [vaibhawvipul/lorenz-attractor-simulation](https://github.com/vaibhawvipul/lorenz-attractor-simulation): A comprehensive implementation of the Lorenz system demonstrating chaos theory through interactive visualizations and animations with extensive customization options.
- [sail-sg/jrystal](https://github.com/sail-sg/jrystal): A JAX-based Differentiable Density Functional Theory Framework for Materials <https://sail-sg.github.io/jrystal/>

## Prob / Bayesian Inference

- [py-why/dowhy](https://github.com/py-why/dowhy): DoWhy is a Python library for causal inference that supports explicit modeling and testing of causal assumptions. DoWhy is based on a unified language for causal inference, combining causal graphical models and potential outcomes frameworks. <https://py-why.github.io/dowhy>
- [pgmpy/pgmpy](https://github.com/pgmpy/pgmpy): Python Library for learning (Structure and Parameter), inference (Probabilistic and Causal), and simulations in Bayesian Networks. <https://pgmpy.org>
- [fmfn/BayesianOptimization](https://github.com/fmfn/BayesianOptimization): A Python implementation of global optimization with gaussian processes.
- [uber/causalml](https://github.com/uber/causalml): Uplift modeling and causal inference with machine learning algorithms
- [pymc-labs/CausalPy](https://github.com/pymc-labs/CausalPy): A Python package for causal inference in quasi-experimental settings <https://causalpy.readthedocs.io>

## Graph

- [apple/ml-gbc](https://github.com/apple/ml-gbc): Graph-based captioning interconnects region captions to form an integral, structured, and fine-grained description of an image. This codebase contains code for the following purposes.
- [naganandy/graph-based-deep-learning-literature](https://github.com/naganandy/graph-based-deep-learning-literature): links to conference publications in graph-based deep learning

## Category for ML

- [bgavran/Category_Theory_Machine_Learning](https://github.com/bgavran/Category_Theory_Machine_Learning): List of papers studying machine learning through the lens of category theory
- [statusfailed/catgrad](https://github.com/statusfailed/catgrad): a categorical deep learning compiler
  - [ArXiv - Reverse derivative categories](https://arxiv.org/abs/1910.07065)

## Misc

- [probml/dynamax](https://github.com/probml/dynamax): State Space Models library in JAX <https://probml.github.io/dynamax/>
- [MichaelTMatthews/Craftax](https://github.com/MichaelTMatthews/Craftax): (Crafter + NetHack) in JAX. ICML 2024 Spotlight.
- [haoliuhl/ringattention](https://github.com/haoliuhl/ringattention): Large Context Attention
- [shap/shap](https://github.com/shap/shap): A game theoretic approach to explain the output of any machine learning model. <https://shap.readthedocs.io>
- [geometric-intelligence/TopoBench](https://github.com/geometric-intelligence/TopoBench): TopoBench is a Python library designed to standardize benchmarking and accelerate research in Topological Deep Learning
